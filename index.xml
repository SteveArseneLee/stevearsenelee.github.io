<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LogLee's Training Ground</title><link>https://stevearsenelee.github.io/</link><description>Recent content on LogLee's Training Ground</description><generator>Hugo -- gohugo.io</generator><language>ko</language><lastBuildDate>Tue, 15 Apr 2025 14:56:52 +0900</lastBuildDate><atom:link href="https://stevearsenelee.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>이걸 해볼까요</title><link>https://stevearsenelee.github.io/docs/infra/kvm/whatswrong/</link><pubDate>Tue, 15 Apr 2025 14:56:52 +0900</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kvm/whatswrong/</guid><description>Worker Node에 Role 부여하기 kubectl label node {node명} node-role.kubernetes.io/worker=worker NFS 서버 연결 및 PersistentVolume, StorageClass 설정 NFS 서버 확인 IP 확인 공유 디렉토리 : e.</description></item><item><title/><link>https://stevearsenelee.github.io/docs/data-engineering/modeling/normalization-vs-denomralization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-engineering/modeling/normalization-vs-denomralization/</guid><description/></item><item><title>1. Process &amp; Thread</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/1-process-thread/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/1-process-thread/</guid><description>1. 정의 프로세스 (Process) 실행 중인 프로그램의 인스턴스 운영체제로부터 독립된 메모리 공간, 자원을 할당받음 자체 주소 공간, 코드 영역, 데이터, 힙, 스택을 가짐 각 프로세스는 **PCB(Process Control Block)**로 커널이 관리 스레드 (Thread) 프로세스 내부에서 실행되는 작업의 흐름 단위 코드, 데이터, 힙, 파일 디스크립터 등을 프로세스 내 다른 스레드와 공유 스택과 레지스터는 독립적으로 가짐 **TCB(Thread Control Block)**로 커널/라이브러리가 관리 2.</description></item><item><title>2. CPU Scheduling</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/2-cpu-scheduling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/2-cpu-scheduling/</guid><description>1. 정의 CPU 스케줄링은 Ready Queue에 있는 프로세스들 중 어떤 프로세스에게 CPU를 할당할지 결정하는 정책.</description></item><item><title>3. 프로세스 동기화(Process Synchronization)</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/3-process-synchronization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/3-process-synchronization/</guid><description>1. 정의 프로세스 동기화란 둘 이상의 프로세스(또는 스레드)가 공유 자원에 접근할 때 충돌 없이 안전하게 작업할 수 있도록 보장하는 방법.</description></item><item><title>4. Deadlock</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/4-deadlock/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/4-deadlock/</guid><description>1. 정의 데드락(교착 상태, Deadlock) 이란 여러 프로세스(또는 스레드)가 서로 자원이 풀리기를 기다리며 무한히 블로킹되어, 더 이상 진행되지 못하는 상태를 의미한다.</description></item><item><title>5. 메모리 관리</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/5-memory-manage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/5-memory-manage/</guid><description>1. 메모리의 계층 구조 및 주소 체계 메모리 계층 구조 CPU -&amp;gt; register -&amp;gt; cache -&amp;gt; main memory(RAM) -&amp;gt; SSD/HDD OS 입장에서는 **main memory(RAM)**을 관리하는 게 핵심 주소 체계 구분 설명 논리 주소(Logical Address) CPU가 생성한 주소 (프로세스 입장에서의 주소) 물리 주소(Physical Address) 실제 메모리 하드웨어 상의 주소 가상 주소(Virtual Address) 논리 주소와 같으며, MMU가 물리 주소로 변환 =&amp;gt; MMU (Memory Management Unit): 논리 주소를 물리 주소로 변환하는 하드웨어.</description></item><item><title>6. 가상 메모리</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/6-virtual-memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/6-virtual-memory/</guid><description>1. 정의 가상 메모리(Virtual Memory) 는 프로세스가 실제 물리 메모리보다 더 큰 주소 공간을 사용할 수 있도록 지원하는 메커니즘</description></item><item><title>7. File System</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/7-file-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/7-file-system/</guid><description>1. 파일 시스템의 역할 데이터를 저장하고, 탐색하고, 보호하는 계층 저장 장치(HDD, SSD 등)의 추상화 계층을 제공 운영체제는 파일 시스템을 통해 파일/디렉토리를 관리함 2.</description></item><item><title>Ceph RBD 설정하기(Block Storage)</title><link>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/rbd-sc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/rbd-sc/</guid><description>Ceph RBD를 Kubernetes PVC로 연동하기 순서는 다음과 같다.
RBD용 Pool 생성 StorageClass 생성 PVC 생성 PVC를 사용하는 테스트 Pod 생성 정상 Mount 여부 확인 1.</description></item><item><title>Ceph 개요 및 구축하기</title><link>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-installation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-installation/</guid><description>Ceph이란? 완전히 분산되고, 확장성과 고가용성을 지향하는 storage platform
핵심 목표</description></item><item><title>Ceph 구축하기 - 요약본</title><link>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-install-guide-short/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-install-guide-short/</guid><description>1. Rook Operator 배포 # 공식 Helm 차트로 설치 helm repo add rook-release https://charts.</description></item><item><title>Ceph 초기 설정하기</title><link>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-tools-pod/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-tools-pod/</guid><description>ceph가 정상적으로 설치됐다면 다음의 설정들을 추가해준다. ceph-tools는 운영자가 다루는 pod라서 따로 추가해줘야한다.</description></item><item><title>CephFS 구축하기</title><link>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-fs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-lake-platform/ceph/ceph-fs/</guid><description>1. CephFS Filesystem 생성 rook-ceph-filesystem.yaml
apiVersion: ceph.rook.io/v1 kind: CephFilesystem metadata: name: rook-ceph-fs namespace: rook-ceph spec: metadataPool: replicated: size: 3 dataPools: - replicated: size: 3 preserveFilesystemOnDelete: true metadataServer: activeCount: 1 activeStandby: true metadataPool, dataPools 모두 replication 3개로 설정(3 OSD) MDS(Metadata Server)는 1 active + 1 standby (HA) 2.</description></item><item><title>Ceph를 구축하며 발생한 cpu 이슈..</title><link>https://stevearsenelee.github.io/docs/troubleshooting/ceph-issue1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/troubleshooting/ceph-issue1/</guid><description>상황 Ceph 클러스터를 Kubernetes에 구축하는 과정 중, csi-rbdplugin, csi-cephfsplugin, csi-snapshotter 등의 csi-* 계열 Pod들이 CrashLoopBackOff 또는 Error 상태로 지속적으로 실패함.</description></item><item><title>Dimensional Modeling: 분석을 위한 데이터 설계의 본질</title><link>https://stevearsenelee.github.io/docs/data-engineering/modeling/dimensional-modeling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-engineering/modeling/dimensional-modeling/</guid><description>Fact와 Dimension의 개념 Fact : &amp;ldquo;측정값 / 수치 중심의 이벤트 데이터&amp;rdquo;</description></item><item><title>Flink to GCS</title><link>https://stevearsenelee.github.io/docs/data-processing/flink/flink-to-gcs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-processing/flink/flink-to-gcs/</guid><description>1. GCP 준비 Bucket 생성 Service account 생성 (최소 권한) Storage Object Admin Storage Object Creator Service account key(Json file) 생성 후 다운로드 2.</description></item><item><title>Hello</title><link>https://stevearsenelee.github.io/docs/infra/kvm/vm-metadata/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kvm/vm-metadata/</guid><description>인프라 구성은 다음과 같다.
Home(192.168.0.19) VM명 Disk CPU RAM Disk 사이즈 ctrl-node /mnt/kvm-pool/ctrl-node.</description></item><item><title>Kafka 심화 개념</title><link>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-basic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-basic/</guid><description>Producer Acks, Batch, Page Cache and Flush acks 설정은 요청이 성공할 때를 정의하는 데 사용되는 Producer에 설정하는 Parameter</description></item><item><title>Kafka 운영 요소</title><link>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-troubleshooting-optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-troubleshooting-optimization/</guid><description>Kafka Monitoring Troubleshooting Zookeeper Troubleshooting Broker Troubleshooting Producer Troubleshooting Consumer Tuning Broker Tuning Producer Tuning Consumer</description></item><item><title>Kafka의 데이터 구조</title><link>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-data-structure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-data-structure/</guid><description>Kafka의 메세지 저장 구조는 논리적 구조와 물리적 구조로 나눠서 생각하는 것이 좋다.</description></item><item><title>Kafka의 성능 측정 (Block storage vs NFS)</title><link>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-storage-performance-test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-storage-performance-test/</guid><description>개요 Kafka docs에는 어디에 데이터를 저장해야한다는 글이 없지만, Kafka를 k8s에 올릴 때 사용하는 strimzi operator에는 다음과 같은 문구가 있다.</description></item><item><title>Kafka의 저장소</title><link>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-storage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/data-integration/kafka/kafka-storage/</guid><description>Kubernetes에서 kafka를 사용할때 kafka의 데이터 저장소는 어떤 것이 적절한지에 대한 글이다.</description></item><item><title>Kubespray로 쉽게 구축하기</title><link>https://stevearsenelee.github.io/docs/infra/kubernetes/install-with-kubespray/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kubernetes/install-with-kubespray/</guid><description>🕒 작성일: 2025-04-15T17:35:26+09:00 ✍️ 작성자: SteveArseneLee
모든 인스턴스에 접근할 수 있는 곳에서 다음과 같은 작업을 실행한다.</description></item><item><title>KVM에서 사용할 Storage 설정</title><link>https://stevearsenelee.github.io/docs/infra/kvm/storage-settings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kvm/storage-settings/</guid><description>1. Logical Volume 생성 물리 저장소에 논리 볼륨을 먼저 할당해준다</description></item><item><title>Prom</title><link>https://stevearsenelee.github.io/docs/observability/metrics/prom-test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/observability/metrics/prom-test/</guid><description>Producer Acks, Batch, Page Cache and Flush acks 설정은 요청이 성공할 때를 정의하는 데 사용되는 Producer에 설정하는 Parameter</description></item><item><title>Test</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/test/</guid><description/></item><item><title>Test</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4/test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4/test/</guid><description/></item><item><title>Todo List</title><link>https://stevearsenelee.github.io/docs/others/todolist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/others/todolist/</guid><description>Todo&amp;hellip; Ingress 설정 Test Kafka 올리기 Done Ceph 올리기</description></item><item><title>Tracing에 대해서...</title><link>https://stevearsenelee.github.io/docs/observability/traces/tracing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/observability/traces/tracing/</guid><description>Tracing이란? microservice가 시스템을 경유하며 transaction 을 처리하는 과정에서 발생하는 세부적인 정보 또한, 트랜잭션이 이동한 경로, 트랜잭션을 처리하는 과정에서 발생하는 대기시간과 지연시간, 병목현상이나 에러를 일으키는 원인을 문맥(context)과 로그, 태그 등의 metadata에 출력함</description></item><item><title>VM 사이즈 변경...</title><link>https://stevearsenelee.github.io/docs/infra/kvm/vm-calc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kvm/vm-calc/</guid><description>vm들을 k8s로 올려놨는데, 너무 부하가 큰듯하다&amp;hellip; 모든걸 다시 계산해봐야겠다.
Main server cpu 16, memory 64gb, ssd 1tb master 2대, worker 2대,</description></item><item><title>VM 생성</title><link>https://stevearsenelee.github.io/docs/infra/kvm/vm-creattion-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kvm/vm-creattion-guide/</guid><description>[준비 단계]
os image 다운로드 받아놓기 Resource 용량 산정 (cpu, memory, disk) ip 설계 (선택) 물리 서버가 n대라면 VM 분배 계획 [실습 단계]</description></item><item><title>VM 생성 간단</title><link>https://stevearsenelee.github.io/docs/infra/kvm/vm-install-simple/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kvm/vm-install-simple/</guid><description>Home에는
#!/bin/bash set -e echo &amp;#34;[HOME SERVER - STORAGE POOL &amp;amp; VOLUME SETUP]&amp;#34; # [1] Storage Pools 생성 echo &amp;#34;[1] Creating storage pools.</description></item><item><title>리소스 이슈 인한 인프라 재구축</title><link>https://stevearsenelee.github.io/docs/troubleshooting/resource-issue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/troubleshooting/resource-issue/</guid><description>상황 다음과 같은 이슈가 발생했다. 현재 구축된 스택은 ceph, minio, kafka, kafka-ui뿐인데, request&amp;amp;limit을 최적화했음에도 내 환경에서는 다소 버거운 것으로 보인다.</description></item><item><title>여러 환경의 클러스터를 손쉽게 관리하기</title><link>https://stevearsenelee.github.io/docs/infra/kubernetes/context-switch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/infra/kubernetes/context-switch/</guid><description>1. 원격 클러스터의 kubeconfig 받아오기 sudo cat /etc/kubernetes/admin.conf 2. 로컬 파일에 저장 내 경우 ~/kubeconfig |- kubeconfig-cluster1 |- kubeconfig-cluster2 |- .</description></item><item><title>정규화 - 1NF, 2NF, 3NF, BCNF</title><link>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4/normalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%B4%EB%A1%A0/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4/normalization/</guid><description>정규화란? 데이터를 효율적으로 관리하기 위해 데이터를 여러 테이블로 나누고, 데이터 중복과 이상 현상을 최소화해 데이터의 일관성을 유지하는 과정</description></item><item><title>하나의 operator와 여러 namespace의 여러 kafka cluster</title><link>https://stevearsenelee.github.io/docs/troubleshooting/kafka-one-operator-multi-kafka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://stevearsenelee.github.io/docs/troubleshooting/kafka-one-operator-multi-kafka/</guid><description>상황 Strimzi Kafka Operator를 하나만 설치한 뒤, 여러 namespace에 Kafka 클러스터를 각각 배포하려는 구조로 운영하고자 했음.</description></item></channel></rss>